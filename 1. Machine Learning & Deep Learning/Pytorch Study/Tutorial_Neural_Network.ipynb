{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "### 0. Nerual Network\n",
    "### 1. nn.Module - Layer & Forward Propagation\n",
    "### 2. Loss Function\n",
    "### 3. Back Propagation\n",
    "### 4. Update weights\n",
    "**+) classes & methods for CNN** (explanations of methods I've taken in this notebook)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Neural Network\n",
    "\n",
    "Neural Network는 torch.nn을 이용해서 만들 수 있다. 특히, NN class를 설계할 때에, torch.nn.Module을 상속받는 경우가 많다.\n",
    "\n",
    "Neural Network를 설계하는 과정은 크게 다음과 같다. (data preprocessing 제외)\n",
    "1. **NN 정의** - layer와 forward propagation의 방식을 NN class의 method를 통해 정의한다.\n",
    "2. 준비한 데이터를 model에 학습시켜, **Loss**를 계산한다\n",
    "3. **Back propagation**을 통해 각 parameter의 gradient 계산\n",
    "4. **Update weight**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. nn.Module - Layer & Forward Propagation\n",
    "\n",
    "Neural Network module을 정의해야 한다. \n",
    "이 때, 거의 모든 NN module은 ``torch.nn.Module``을 상속한다.(NN module의 base class)\n",
    "\n",
    "nn.module을 *상속*하므로, ``super`` 사용 필요\n",
    "\n",
    "### Layer\n",
    "주로 ``__init__()``에서, 필요한 layer들을 정의한다. 밑의 예시는 CNN을 build하는 과정이므로 convolution layer, full-connected layer를 정의하였다(ReLU나 Max Pooling은 함수로 표현).\n",
    "\n",
    "### forward\n",
    "Forward Propagation 과정(데이터가 input으로 들어와서 최종 결과값을 뱉는 과정)을 직접 설계해야 한다. ``torch.nn.functional`` class를 많이 활용한다.\n",
    "\n",
    " ``torch.nn.functional``: nn의 데이터가 거치는 다양한 종류의 함수를 담은 class로, convolution, loss, pooling, normalizing, dropout 등의 다양한 function을 가지고 있다.\n",
    "    https://pytorch.org/docs/stable/nn.functional.html\n",
    "    \n",
    "### Dimension 주의!\n",
    "다양한 layer를 만들고 forward에서 여러 연산을 취하는 과정에서, data의 dimension이 잘 맞는 지 확인하는 과정은 매우 중요하다.\n",
    "\n",
    "nn이 학습하는 ``torch.size``는 보통 4개의 element로 이루어져 있다 - torch.size([a, b, c, d])\n",
    "* a: batch size\n",
    "* b: # of channel. 첫 input의 # of channel은 # of color와 같은 의미를 가진다\n",
    "* c, d: channel(matrix) size\n",
    "\n",
    "아래 코드의 dimension을 따지는 연습은 notebook의 마지막 파트인 *classes & methods for CNN*에서 다룬다.\n",
    "\n",
    "### Why no backward?\n",
    "``autograd``에 의해 backward function은 이미 define됨.\n",
    "따라서, 따로 구현할 필요가 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # conv layer\n",
    "        self.conv1= nn.Conv2d(1, 6, 3)\n",
    "        self.conv2= nn.Conv2d(6, 16, 3)\n",
    "        \n",
    "        # fully connected layer\n",
    "        self.fc1= nn.Linear(16*6*6, 120)\n",
    "        self.fc2= nn.Linear(120, 84)\n",
    "        self.fc3= nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x= F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x= F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        \n",
    "        # Flattening\n",
    "        x= x.view(-1, self.num_flat_features(x))\n",
    "        \n",
    "        # Fully connecting\n",
    "        # why ReLU here? + no ReLU at last layer\n",
    "        x= F.relu(self.fc1(x))\n",
    "        x= F.relu(self.fc2(x))\n",
    "        x= self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    # flattening과정에 넣을 dimension 계산 - batch dimension을 제외한 나머지 dimension의 곱 return\n",
    "    def num_flat_features(self, x):\n",
    "        size= x.size()[1:] # all dimensions except the batch dimension\n",
    "        num_features= 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        \n",
    "        return num_features\n",
    "        \n",
    "    \n",
    "net= Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "\n",
      "params  1\n",
      "torch.Size([6, 1, 3, 3])\n",
      "-------------\n",
      "params  2\n",
      "torch.Size([6])\n",
      "-------------\n",
      "params  3\n",
      "torch.Size([16, 6, 3, 3])\n",
      "-------------\n",
      "params  4\n",
      "torch.Size([16])\n",
      "-------------\n",
      "params  5\n",
      "torch.Size([120, 576])\n",
      "-------------\n",
      "params  6\n",
      "torch.Size([120])\n",
      "-------------\n",
      "params  7\n",
      "torch.Size([84, 120])\n",
      "-------------\n",
      "params  8\n",
      "torch.Size([84])\n",
      "-------------\n",
      "params  9\n",
      "torch.Size([10, 84])\n",
      "-------------\n",
      "params  10\n",
      "torch.Size([10])\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "params= list(net.parameters())\n",
    "print(len(params))\n",
    "print()\n",
    "for i in range(len(params)):\n",
    "    print(\"params \", i+1)\n",
    "    print(params[i].size())\n",
    "    print('-------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameters\n",
    "``torch.nn.Module.parameters()`` - **learnable parameter** 반환\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Question</h4><p> parameter의 size는 어떻게 결정되는걸까? 대충 홀수번째 parameter는 output/input 순으로, 짝수번쨰 parameter는 output을 size로 가지는 것 같은데... 조금 더 고민 필요 </p></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loss Function\n",
    "\n",
    "``torch.nn``에는 다양한 loss function이 있다 (링크: https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
    "\n",
    "* ``nn.L1Loss``: Mean Absolute Error\n",
    "* ``nn.MSELoss``: Mean Squared Error\n",
    "* ``nn.CrossEntropyLoss``: CrossEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2659, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "input_= torch.randn(1, 1, 32, 32)\n",
    "output= net(input_)\n",
    "target= torch.randn(10)\n",
    "target= target.view(1, -1)\n",
    "\n",
    "criterion= nn.MSELoss()\n",
    "loss= criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Back Propagation\n",
    "\n",
    "Loss를 계산하였으니, back propagation을 진행해야 함.\n",
    "\n",
    "loss.grad_fn에는 loss까지 거쳐왔던 연산들이 저장되어 있고, .backward()를 사용하여 그 연산에 사용된 tensor들의 gradient를 받을 수 있다(단 requires_grad= True인 tensor에 한함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x7fdb4fb51eb0>\n",
      "<AddmmBackward object at 0x7fdb4fb512e0>\n",
      "<AccumulateGrad object at 0x7fdb4fb51eb0>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn) #MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0]) # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0]) # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next_functions에 그동안의 연산(grad_fn)이 저장됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back propagate를 진행하기 전에, exisiting gradients를 clear해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "None\n",
      "conv1.bias.grad after backward\n",
      "tensor([ 0.0137,  0.0088,  0.0083,  0.0062, -0.0130, -0.0178])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()\n",
    "\n",
    "print(\"conv1.bias.grad before backward\")\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Update wieghts\n",
    "\n",
    "``torch.optim`` package에는 다양한 optimizing algorithm이 존재함. \n",
    "1. optimizer를 NN의 parameter를 parameter로 받아 call 하고\n",
    "2. .backward()를 실행하고\n",
    "3. optimizer의 .step()을 이용해 optimize!\n",
    "\n",
    "**Optimizing Algorithm**\n",
    "* Adam\n",
    "* SGD\n",
    "* etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer= optim.SGD(net.parameters(), lr= 0.01)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "output= net(input_)\n",
    "loss= criterion(output, target)\n",
    "loss.backward()\n",
    "\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## + Classes & Methods for CNN\n",
    "\n",
    "**CNN**은 크게 4가지 과정으로 설계된다.\n",
    "1. Convolution layer (+ReLU)\n",
    "2. Pooling layer (1-2 몇번 반복)\n",
    "3. Flattening\n",
    "4. Fully connected layer\n",
    "\n",
    "### 1. Convolution layer\n",
    "``torch.nn.Conv2d()``\n",
    "* in_channels(int): input image의 channel 수 - conv1의 경우 color의 수\n",
    "* out_channels(int): convolution 후의 channel 수\n",
    "* kernel_size(int/tuple): filter 크기. square matrix를 filter로 쓸 경우 int만 써도 ok.\n",
    "\n",
    "### 2. Pooling\n",
    "``torch.nn.functional.max_pool2d()``\n",
    "\n",
    "max pooling을 하는 method.\n",
    "* input(tensor): pooling시킬 data. 보통 ReLU와 Convoluiton을 취한 data를 전달해 준다.\n",
    "* weight(int/tuple): pooling의 kernel로 사용할 matrix의 size. \n",
    "\n",
    "### 3. Flattening\n",
    "``torch.view()``\n",
    "\n",
    "numpy의 reshape method에 해당\n",
    "\n",
    "CNN의 학습 과정에서는 Flattening에 사용한다.\n",
    "\n",
    "(-1, (# of channel) x (# of elements in channel))\n",
    "\n",
    "### 4. Fully connected layer\n",
    "``torch.nn.Linear()``\n",
    "* in_features(int): input sample의 size\n",
    "* out_feattures(int): output sample의 size\n",
    "\n",
    "첫번째 fully connected layer의 경우, matrix가 flattening 후 전돨되므로 in_feauters = (# of channels) x (# of elements in channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimension 따지기\n",
    "(a, b, c, d)\n",
    "    * a: batch size\n",
    "    * b: # of channel(matrix, color)\n",
    "    * c,d: matrix size\n",
    "\n",
    "* Input: (1, 1, 32, 32) - data-dependent\n",
    "* after conv1: (1, 6, 30, 30) - conv1의 kernel size가 3이므로, 양 끝 row/column 1개씩이 버려진다.\n",
    "* after pooling1: (1, 6, 15, 15) - pooling의 kernel size가 2이므로, 30 % 2 = 15. ReLU는 size에 영향을 주지 못함\n",
    "* after conv2: (1, 16, 13, 13)\n",
    "* after pooling2: (1, 16, 6, 6)\n",
    "* after flattening: (-1, 16x6x6)\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Question</h4><p> Pooling2에서 13/2가 7이 아니라 6이 나오나? 맨 마지막 row/column은 그냥 버리는겨? </p></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
