{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning을 사용한 Recommendation System\n",
    "\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "### [1. Matrix Factorization to DL (w/o hidden layer)](http://localhost:8888/notebooks/Desktop/dev/RecSys/python을%20이용한%20개인화%20추천시스템/notes/Deep%20Learning%20Model%20for%20RecSys.ipynb#Matrix-Factorization-to-DL---w/o-hidden-layer)\n",
    "Matrix Factorization에서 사용한 개념 - User와 Item을 공통으로 설명할 수 있는 **Latent Factor**가 있을 것이라는 아이디어 - 를 사용한다.\n",
    "\n",
    "1. User(Item) Data를 Embedding하는 layer인 User Embedding(Item Embedding)을 만든다. \n",
    "2. User Embedding과 Item Embedding을 dot product하여 두 layer를 합친다.\n",
    "3. Product Layer에 User bias / Item bias matrix를 더하여 Output을 만든다.\n",
    "\n",
    "### [2. Matrix Factorization to DL (with hidden layers)](http://localhost:8888/notebooks/Desktop/dev/RecSys/python을%20이용한%20개인화%20추천시스템/notes/Deep%20Learning%20Model%20for%20RecSys.ipynb#Matrix-Factorization-to-DL-with-hidden-layer)\n",
    "\n",
    "사실 1번에서 다룬 model은 hidden layer가 없다. 그리고 어차피 여러 층의 hidden layer를 거칠거라면, user embedded matrix와 item embedded matrix를 product 할 필요는 없다. User embedding, Item embedding, user bias, item bias를 flatten하여 concatenate한 후, 여러 layer를 통해 학습시키면 충분하다.\n",
    "\n",
    "\n",
    "### [3. Add Variables to Model](http://localhost:8888/notebooks/Desktop/dev/RecSys/python을%20이용한%20개인화%20추천시스템/notes/Deep%20Learning%20Model%20for%20RecSys.ipynb#Add-Variables-to-Model)\n",
    "\n",
    "직접적인 평점 데이터 이외의 다른 데이터를 사용하려면(ex. user의 특성에 관한 데이터), embedding layer와 bias matrix를 concatenate할 때, 같이 합쳐 줄 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Matrix Factorization to DL - w/o hidden layer\n",
    "\n",
    "#### First Layer - Input\n",
    "* User (One hot representation)\n",
    "* Item (One hot representation)\n",
    "\n",
    "#### Second Layer - Embedding\n",
    "* User Embedding\n",
    "* Item Embedding\n",
    "\n",
    "#### Dot\n",
    "* dot product User Embedding & Item Embedding\n",
    "\n",
    "#### Add\n",
    "* Producted Data\n",
    "* User Bias Embedding\n",
    "* Item Bias Embedding\n",
    "\n",
    "#### Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv('/Users/jisujung/Desktop/dev/RecSys/python을 이용한 개인화 추천시스템/data/u.data', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "ratings= ratings[['user_id', 'movie_id', 'rating']].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train_Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "TRAIN_SIZE= 0.5\n",
    "ratings= shuffle(ratings)\n",
    "cutoff= int(TRAIN_SIZE * len(ratings))\n",
    "ratings_train= ratings.iloc[:cutoff]\n",
    "ratings_test=  ratings.iloc[:cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "K= 200\n",
    "mu= ratings_train.rating.mean()\n",
    "M= len(set(ratings.user_id)) + 1\n",
    "N= len(set(ratings.movie_id)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dot, Add, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import SGD, Adamax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embedding**\n",
    "\n",
    "이전 Layer 층과 연결된 다음 Layer를 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user= Input(shape=(1, ))\n",
    "item= Input(shape=(1, ))\n",
    "\n",
    "P_embedding= Embedding(M, K, embeddings_regularizer= l2())(user)\n",
    "Q_embedding= Embedding(N, K, embeddings_regularizer= l2())(item)\n",
    "user_bias= Embedding(M, 1, embeddings_regularizer= l2())(user)\n",
    "item_bias= Embedding(N, 1, embeddings_regularizer= l2())(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "R= layers.dot([P_embedding, Q_embedding], axes=2)\n",
    "R= layers.add([R, user_bias, item_bias])\n",
    "R= Flatten()(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Model(inputs=[user, item], outputs= R)\n",
    "model.compile(\n",
    "    loss=RMSE,\n",
    "    optimizer= SGD(),\n",
    "    metrics= [RMSE]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 200)       188800      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 200)       336600      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 1, 1)         0           embedding[0][0]                  \n",
      "                                                                 embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 1)         944         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 1)         1683        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 1, 1)         0           dot[0][0]                        \n",
      "                                                                 embedding_2[0][0]                \n",
      "                                                                 embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1)            0           add[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 528,027\n",
      "Trainable params: 528,027\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 5.4377 - RMSE: 1.1272 - val_loss: 5.1858 - val_RMSE: 1.1223\n",
      "Epoch 2/60\n",
      "196/196 [==============================] - 0s 3ms/step - loss: 5.1107 - RMSE: 1.1252 - val_loss: 4.8780 - val_RMSE: 1.1209\n",
      "Epoch 3/60\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 4.8068 - RMSE: 1.1219 - val_loss: 4.5935 - val_RMSE: 1.1196\n",
      "Epoch 4/60\n",
      "196/196 [==============================] - 0s 3ms/step - loss: 4.5283 - RMSE: 1.1211 - val_loss: 4.3304 - val_RMSE: 1.1184\n",
      "Epoch 5/60\n",
      "196/196 [==============================] - 0s 3ms/step - loss: 4.2654 - RMSE: 1.1150 - val_loss: 4.0872 - val_RMSE: 1.1172\n",
      "Epoch 6/60\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 4.0341 - RMSE: 1.1211 - val_loss: 3.8624 - val_RMSE: 1.1161\n",
      "Epoch 7/60\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 3.8115 - RMSE: 1.1179 - val_loss: 3.6545 - val_RMSE: 1.1151\n",
      "Epoch 8/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 3.6016 - RMSE: 1.1109 - val_loss: 3.4623 - val_RMSE: 1.1141\n",
      "Epoch 9/60\n",
      "196/196 [==============================] - 0s 3ms/step - loss: 3.4160 - RMSE: 1.1127 - val_loss: 3.2846 - val_RMSE: 1.1131\n",
      "Epoch 10/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 3.2452 - RMSE: 1.1152 - val_loss: 3.1203 - val_RMSE: 1.1122\n",
      "Epoch 11/60\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 3.0808 - RMSE: 1.1110 - val_loss: 2.9684 - val_RMSE: 1.1113\n",
      "Epoch 12/60\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 2.9317 - RMSE: 1.1100 - val_loss: 2.8280 - val_RMSE: 1.1105\n",
      "Epoch 13/60\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 2.7933 - RMSE: 1.1086 - val_loss: 2.6982 - val_RMSE: 1.1098\n",
      "Epoch 14/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 2.6668 - RMSE: 1.1087 - val_loss: 2.5782 - val_RMSE: 1.1090\n",
      "Epoch 15/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 2.5550 - RMSE: 1.1138 - val_loss: 2.4672 - val_RMSE: 1.1083\n",
      "Epoch 16/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 2.4420 - RMSE: 1.1090 - val_loss: 2.3646 - val_RMSE: 1.1076\n",
      "Epoch 17/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 2.3449 - RMSE: 1.1118 - val_loss: 2.2697 - val_RMSE: 1.1070\n",
      "Epoch 18/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 2.2462 - RMSE: 1.1055 - val_loss: 2.1820 - val_RMSE: 1.1064\n",
      "Epoch 19/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 2.1593 - RMSE: 1.1040 - val_loss: 2.1010 - val_RMSE: 1.1058\n",
      "Epoch 20/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 2.0876 - RMSE: 1.1113 - val_loss: 2.0260 - val_RMSE: 1.1052\n",
      "Epoch 21/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 2.0063 - RMSE: 1.1029 - val_loss: 1.9567 - val_RMSE: 1.1047\n",
      "Epoch 22/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.9412 - RMSE: 1.1053 - val_loss: 1.8926 - val_RMSE: 1.1042\n",
      "Epoch 23/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.8807 - RMSE: 1.1071 - val_loss: 1.8334 - val_RMSE: 1.1037\n",
      "Epoch 24/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.8151 - RMSE: 1.0991 - val_loss: 1.7786 - val_RMSE: 1.1033\n",
      "Epoch 25/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.7691 - RMSE: 1.1064 - val_loss: 1.7280 - val_RMSE: 1.1028\n",
      "Epoch 26/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.7183 - RMSE: 1.1048 - val_loss: 1.6811 - val_RMSE: 1.1024\n",
      "Epoch 27/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.6728 - RMSE: 1.1047 - val_loss: 1.6379 - val_RMSE: 1.1020\n",
      "Epoch 28/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.6248 - RMSE: 1.0988 - val_loss: 1.5978 - val_RMSE: 1.1016\n",
      "Epoch 29/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.5888 - RMSE: 1.1017 - val_loss: 1.5608 - val_RMSE: 1.1012\n",
      "Epoch 30/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.5535 - RMSE: 1.1024 - val_loss: 1.5266 - val_RMSE: 1.1009\n",
      "Epoch 31/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.5205 - RMSE: 1.1025 - val_loss: 1.4950 - val_RMSE: 1.1006\n",
      "Epoch 32/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.4894 - RMSE: 1.1021 - val_loss: 1.4658 - val_RMSE: 1.1002\n",
      "Epoch 33/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.4572 - RMSE: 1.0983 - val_loss: 1.4387 - val_RMSE: 1.0999\n",
      "Epoch 34/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.4278 - RMSE: 1.0951 - val_loss: 1.4137 - val_RMSE: 1.0997\n",
      "Epoch 35/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.4063 - RMSE: 1.0979 - val_loss: 1.3906 - val_RMSE: 1.0994\n",
      "Epoch 36/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.3853 - RMSE: 1.0992 - val_loss: 1.3693 - val_RMSE: 1.0991\n",
      "Epoch 37/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.3642 - RMSE: 1.0988 - val_loss: 1.3495 - val_RMSE: 1.0989\n",
      "Epoch 38/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.3425 - RMSE: 1.0962 - val_loss: 1.3313 - val_RMSE: 1.0986\n",
      "Epoch 39/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.3300 - RMSE: 1.1014 - val_loss: 1.3144 - val_RMSE: 1.0984\n",
      "Epoch 40/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.3080 - RMSE: 1.0957 - val_loss: 1.2988 - val_RMSE: 1.0982\n",
      "Epoch 41/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.2951 - RMSE: 1.0979 - val_loss: 1.2843 - val_RMSE: 1.0980\n",
      "Epoch 42/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.2806 - RMSE: 1.0974 - val_loss: 1.2710 - val_RMSE: 1.0978\n",
      "Epoch 43/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.2661 - RMSE: 1.0958 - val_loss: 1.2586 - val_RMSE: 1.0976\n",
      "Epoch 44/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.2555 - RMSE: 1.0971 - val_loss: 1.2472 - val_RMSE: 1.0974\n",
      "Epoch 45/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.2422 - RMSE: 1.0948 - val_loss: 1.2367 - val_RMSE: 1.0972\n",
      "Epoch 46/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.2312 - RMSE: 1.0940 - val_loss: 1.2269 - val_RMSE: 1.0970\n",
      "Epoch 47/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.2249 - RMSE: 1.0970 - val_loss: 1.2179 - val_RMSE: 1.0969\n",
      "Epoch 48/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.2120 - RMSE: 1.0928 - val_loss: 1.2096 - val_RMSE: 1.0967\n",
      "Epoch 49/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.2096 - RMSE: 1.0984 - val_loss: 1.2019 - val_RMSE: 1.0966\n",
      "Epoch 50/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.1972 - RMSE: 1.0934 - val_loss: 1.1948 - val_RMSE: 1.0964\n",
      "Epoch 51/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.1903 - RMSE: 1.0934 - val_loss: 1.1882 - val_RMSE: 1.0963\n",
      "Epoch 52/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.1885 - RMSE: 1.0979 - val_loss: 1.1821 - val_RMSE: 1.0962\n",
      "Epoch 53/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.1751 - RMSE: 1.0904 - val_loss: 1.1764 - val_RMSE: 1.0961\n",
      "Epoch 54/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.1739 - RMSE: 1.0946 - val_loss: 1.1712 - val_RMSE: 1.0959\n",
      "Epoch 55/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.1700 - RMSE: 1.0956 - val_loss: 1.1664 - val_RMSE: 1.0958\n",
      "Epoch 56/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.1653 - RMSE: 1.0956 - val_loss: 1.1620 - val_RMSE: 1.0957\n",
      "Epoch 57/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.1597 - RMSE: 1.0943 - val_loss: 1.1579 - val_RMSE: 1.0956\n",
      "Epoch 58/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.1541 - RMSE: 1.0926 - val_loss: 1.1541 - val_RMSE: 1.0955\n",
      "Epoch 59/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.1489 - RMSE: 1.0910 - val_loss: 1.1505 - val_RMSE: 1.0954\n",
      "Epoch 60/60\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 1.1456 - RMSE: 1.0911 - val_loss: 1.1473 - val_RMSE: 1.0953\n"
     ]
    }
   ],
   "source": [
    "result= model.fit(\n",
    "    x= [ratings_train.user_id.values, ratings_train.movie_id.values],\n",
    "    y= ratings_train.rating.values -  mu,\n",
    "    epochs= 60,\n",
    "    batch_size= 256,\n",
    "    validation_data=(\n",
    "        [ratings_test.user_id.values, ratings_test.movie_id.values],\n",
    "        ratings_test.rating.values - mu\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(result.history['RMSE'], label=\"Train RMSE\")\n",
    "plt.plot(result.history['val_RMSE'], label= \"Test RMSE\")\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict sample values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actuals: \n",
      " 38078    2\n",
      "5060     1\n",
      "68190    4\n",
      "5929     5\n",
      "81301    2\n",
      "97539    3\n",
      "Name: rating, dtype: int64\n",
      "\n",
      "Predictions: \n",
      " [[3.536372 ]\n",
      " [3.4306452]\n",
      " [3.5478108]\n",
      " [3.6021094]\n",
      " [3.5395792]\n",
      " [3.5364323]]\n"
     ]
    }
   ],
   "source": [
    "user_ids= ratings_test.user_id.values[:6]\n",
    "movie_ids= ratings_test.movie_id.values[:6]\n",
    "\n",
    "predictions= model.predict([user_ids, movie_ids]) + mu\n",
    "\n",
    "print(\"Actuals: \\n\", ratings_test.rating[:6])\n",
    "print()\n",
    "print(\"Predictions: \\n\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0958504318720563"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def RMSE2(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred)) ** 2))\n",
    "\n",
    "user_ids= ratings_test.user_id.values\n",
    "movie_ids= ratings_test.movie_id.values\n",
    "\n",
    "y_pred= model.predict([user_ids, movie_ids]) + mu\n",
    "y_pred= np.ravel(y_pred, order= \"C\")\n",
    "y_true= np.array(ratings_test.rating)\n",
    "\n",
    "RMSE2(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Matrix Factorization to DL with hidden layer\n",
    "\n",
    "#### First Layer - Input\n",
    "* User (One hot representation)\n",
    "* Item (One hot representation)\n",
    "\n",
    "#### Second Layer - Embedding\n",
    "* User Embedding\n",
    "* Item Embedding\n",
    "\n",
    "#### Concatenate\n",
    "Concatenate 4 layers for mapping model\n",
    "* User Embedding\n",
    "* Item Embedding\n",
    "* User bias\n",
    "* Item bias\n",
    "\n",
    "#### Hidden Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv('/Users/jisujung/Desktop/dev/RecSys/python을 이용한 개인화 추천시스템/data/u.data', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "ratings= ratings[['user_id', 'movie_id', 'rating']].astype(int)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "train_size= 0.75\n",
    "ratings= shuffle(ratings)\n",
    "cutoff= int(train_size * len(ratings))\n",
    "ratings_train= ratings.iloc[:cutoff]\n",
    "ratings_test= ratings.iloc[cutoff:]\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "K= 200\n",
    "mu= ratings_train.rating.mean()\n",
    "M= ratings.user_id.max() + 1\n",
    "N= ratings.movie_id.max() + 1\n",
    "\n",
    "def RMSE(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "#### Initialize Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "user= Input(shape=(1, ))\n",
    "item= Input(shape=(1, ))\n",
    "\n",
    "P_embedding= Embedding(M, K, embeddings_regularizer= l2())(user)\n",
    "Q_embedding= Embedding(N, K, embeddings_regularizer= l2())(item)\n",
    "\n",
    "user_bias= Embedding(M, 1, embeddings_regularizer= l2())(user)\n",
    "item_bias= Embedding(N, 1, embeddings_regularizer= l2())(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Concatenate, Activation\n",
    "P_embedding= Flatten()(P_embedding)\n",
    "Q_embedding= Flatten()(Q_embedding)\n",
    "user_bias= Flatten()(user_bias)\n",
    "item_bias= Flatten()(item_bias)\n",
    "\n",
    "R= Concatenate()([P_embedding, Q_embedding, user_bias, item_bias])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "R= Dense(2048)(R)\n",
    "R= Activation('linear')(R)\n",
    "R= Dense(256)(R)\n",
    "R= Activation('linear')(R)\n",
    "R= Dense(1)(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Model(inputs= [user, item], outputs= R)\n",
    "model.compile(\n",
    "    loss= RMSE,\n",
    "    optimizer= SGD(),\n",
    "    metrics= [RMSE]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 200)       188800      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 200)       336600      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 1)         944         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 1, 1)         1683        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 200)          0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 200)          0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 1)            0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 1)            0           embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 402)          0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2048)         825344      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 2048)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          524544      activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            257         activation_1[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,878,172\n",
      "Trainable params: 1,878,172\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result= model.fit(\n",
    "    x= [ratings_train.user_id.values, ratings_train.movie_id.values],\n",
    "    y= ratings_train.rating.values - mu,\n",
    "    epochs= 65,\n",
    "    batch_size= 512,\n",
    "    validation_data=(\n",
    "        [ratings_test.user_id.values, ratings_test.movie_id.values],\n",
    "        ratings_test.rating.values - mu\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Add Variables to Model\n",
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv('/Users/jisujung/Desktop/dev/RecSys/python을 이용한 개인화 추천시스템/data/u.data', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "ratings= ratings[['user_id', 'movie_id', 'rating']].astype(int)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "train_size= 0.75\n",
    "ratings= shuffle(ratings)\n",
    "cutoff= int(train_size * len(ratings))\n",
    "ratings_train= ratings.iloc[:cutoff]\n",
    "ratings_test= ratings.iloc[cutoff:]\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "K= 200\n",
    "mu= ratings_train.rating.mean()\n",
    "M= ratings.user_id.max() + 1\n",
    "N= ratings.movie_id.max() + 1\n",
    "\n",
    "def RMSE(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'administrator',\n",
       " 'artist',\n",
       " 'doctor',\n",
       " 'educator',\n",
       " 'engineer',\n",
       " 'entertainment',\n",
       " 'executive',\n",
       " 'healthcare',\n",
       " 'homemaker',\n",
       " 'lawyer',\n",
       " 'librarian',\n",
       " 'marketing',\n",
       " 'none',\n",
       " 'other',\n",
       " 'programmer',\n",
       " 'retired',\n",
       " 'salesman',\n",
       " 'scientist',\n",
       " 'student',\n",
       " 'technician',\n",
       " 'writer'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_cols= ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users= pd.read_csv('/Users/jisujung/Desktop/dev/RecSys/python을 이용한 개인화 추천시스템/data/u.user', sep='|', names= u_cols, encoding= 'latin-1')\n",
    "users= users[['user_id', 'occupation']]\n",
    "\n",
    "set(users.occupation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert occupation (str -> int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation= {}\n",
    "def convert_occ(x):\n",
    "    if x in occupation:\n",
    "        return occupation[x]\n",
    "    else:\n",
    "        occupation[x]= len(occupation)\n",
    "        return occupation[x]\n",
    "    \n",
    "users['occupation']= users['occupation'].apply(convert_occ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge ratings data and user occupation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "L= len(occupation)\n",
    "\n",
    "train_occ= pd.merge(ratings_train, users, on= 'user_id')['occupation']\n",
    "test_occ= pd.merge(ratings_test, users, on= 'user_id')['occupation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "#### Initialzing Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = Input(shape=(1, ))\n",
    "item = Input(shape=(1, ))\n",
    "\n",
    "P_embedding = Embedding(M, K, embeddings_regularizer=l2())(user)\n",
    "Q_embedding = Embedding(N, K, embeddings_regularizer=l2())(item)\n",
    "user_bias = Embedding(M, 1, embeddings_regularizer=l2())(user)\n",
    "item_bias = Embedding(N, 1, embeddings_regularizer=l2())(item)\n",
    "\n",
    "occ= Input(shape=(1, ))\n",
    "# 3개인 이유는 없음! K를 정하는 것과 같음\n",
    "occ_embedding= Embedding(L, 3, embeddings_regularizer= l2())(occ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flattening layers to concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Concatenate, Activation\n",
    "\n",
    "P_embedding= Flatten()(P_embedding)\n",
    "Q_embedding= Flatten()(Q_embedding)\n",
    "user_bias= Flatten()(user_bias)\n",
    "item_bias= Flatten()(item_bias)\n",
    "\n",
    "occ_layer= Flatten()(occ_embedding)\n",
    "\n",
    "\n",
    "R= Concatenate()([P_embedding, Q_embedding, user_bias, item_bias, occ_layer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "R= Dense(2048)(R)\n",
    "R= Activation('linear')(R)\n",
    "R= Dense(256)(R)\n",
    "R= Activation('linear')(R)\n",
    "R= Dense(1)(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Model(inputs=[user, item, occ], outputs= R)\n",
    "model.compile(\n",
    "    loss= RMSE,\n",
    "    optimizer= SGD(),\n",
    "    metrics= [RMSE]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 1, 200)       188800      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 1, 200)       336600      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 1, 1)         944         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 1, 1)         1683        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 1, 3)         63          input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 200)          0           embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 200)          0           embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 1)            0           embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 1)            0           embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 3)            0           embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 405)          0           flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "                                                                 flatten_7[0][0]                  \n",
      "                                                                 flatten_8[0][0]                  \n",
      "                                                                 flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2048)         831488      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 2048)         0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          524544      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            257         activation_3[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,884,379\n",
      "Trainable params: 1,884,379\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit(\n",
    "  x=[ratings_train.user_id.values, ratings_train.movie_id.values, train_occ.values],\n",
    "  y=ratings_train.rating.values - mu,\n",
    "  epochs=65,\n",
    "  batch_size=512,\n",
    "  validation_data=(\n",
    "    [ratings_test.user_id.values, ratings_test.movie_id.values, test_occ.values],\n",
    "    ratings_test.rating.values - mu\n",
    "  )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
